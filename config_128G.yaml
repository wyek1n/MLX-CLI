adapter_path: /Users/wyek1n/Downloads/MLX/adapter/Qwen2.5-0.5B-Instruct
data_path: /Users/wyek1n/Downloads/Code/MLX/MLX-CLI/lora/data
model: /Users/wyek1n/Downloads/MLX/model/Qwen2.5-0.5B-Instruct
train: true
fine_tune_type: lora
seed: 0
num_layers: 16  # 可尝试 24
batch_size: 8   # 可尝试 16
iters: 1000     # 可根据 LOSS 增加到 2000
val_batches: 25 # 可尝试 50
learning_rate: 1e-5  # 可尝试 5e-5
steps_per_report: 10
steps_per_eval: 200
resume_adapter_file: null
save_every: 100
test: false
test_batches: 100
max_seq_length: 2048  # 可尝试 4096
grad_checkpoint: false

lora_parameters:
  keys: ["self_attn.q_proj", "self_attn.v_proj"]
  rank: 8    # 可尝试 16
  scale: 20.0
  dropout: 0.0  # 可尝试 0.1