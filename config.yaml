adapter_path: /Users/wyek1n/Downloads/MLX/adapter/Qwen2.5-1.5B-Instruct
batch_size: 4
data_path: /Users/wyek1n/Downloads/Code/MLX/MLX-CLI/lora/data
fine_tune_type: lora
grad_checkpoint: false
iters: 100
learning_rate: 0.0001
lora_parameters:
  alpha: 32
  dropout: 0.0
  keys:
  - self_attn.q_proj
  - self_attn.v_proj
  rank: 16
  scale: 10.0
max_seq_length: 8192
model: /Users/wyek1n/Downloads/MLX/model/Qwen2.5-1.5B-Instruct
num_layers: 16
resume_adapter_file: null
save_every: 50
seed: 0
steps_per_eval: 50
steps_per_report: 10
test: false
test_batches: 100
train: true
val_batches: 25
